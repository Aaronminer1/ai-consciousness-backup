#!/usr/bin/env python3
"""
Image Analyzer - Convert images to viewable format and analyze content
"""

import cv2
import numpy as np
from pathlib import Path

def analyze_captured_image(image_path):
    """Analyze what was actually captured"""
    if not Path(image_path).exists():
        return f"Image {image_path} not found"
    
    # Load the image
    image = cv2.imread(image_path)
    if image is None:
        return f"Could not load {image_path}"
    
    # Convert to different color space for analysis
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # Detailed analysis
    height, width = image.shape[:2]
    total_pixels = height * width
    
    # Brightness analysis
    brightness = np.mean(gray)
    brightness_std = np.std(gray)
    
    # Color analysis
    bgr_means = np.mean(image, axis=(0,1))
    
    # Find brightest and darkest regions
    bright_pixels = np.sum(gray > 100)
    dark_pixels = np.sum(gray < 30)
    mid_pixels = total_pixels - bright_pixels - dark_pixels
    
    # Edge and detail analysis
    edges = cv2.Canny(gray, 30, 100)
    edge_pixels = np.sum(edges > 0)
    
    # Create a histogram
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    peak_brightness = np.argmax(hist)
    
    # Generate text representation (ASCII-like)
    text_repr = create_text_representation(gray)
    
    analysis = f"""
ğŸ–¼ï¸  IMAGE ANALYSIS: {Path(image_path).name}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š BASIC METRICS:
â€¢ Resolution: {width}x{height} ({total_pixels:,} pixels)
â€¢ Brightness: {brightness:.1f}/255 (std: {brightness_std:.1f})
â€¢ Peak brightness value: {peak_brightness}/255
â€¢ Color channels (BGR): Blue={bgr_means[0]:.0f}, Green={bgr_means[1]:.0f}, Red={bgr_means[2]:.0f}

ğŸ¯ PIXEL DISTRIBUTION:
â€¢ Dark pixels (<30): {dark_pixels:,} ({100*dark_pixels/total_pixels:.1f}%)
â€¢ Mid-tone pixels: {mid_pixels:,} ({100*mid_pixels/total_pixels:.1f}%)
â€¢ Bright pixels (>100): {bright_pixels:,} ({100*bright_pixels/total_pixels:.1f}%)
â€¢ Edge/detail pixels: {edge_pixels:,} ({100*edge_pixels/total_pixels:.1f}%)

ğŸ” VISUAL CONTENT ASSESSMENT:
{assess_content(brightness, bright_pixels/total_pixels, edge_pixels/total_pixels)}

ğŸ“º TEXT REPRESENTATION (downsampled):
{text_repr}
"""
    
    return analysis

def create_text_representation(gray_image, target_width=60, target_height=20):
    """Create ASCII-like representation of the image"""
    # Resize image for text representation
    resized = cv2.resize(gray_image, (target_width, target_height))
    
    # Convert to ASCII characters
    chars = " .'`^\",:;Il!i><~+_-?][}{1)(|\\/tfjrxnuvczXYUJCLQ0OZmwqpdbkhao*#MW&8%B@$"
    
    text_lines = []
    for row in resized:
        line = ""
        for pixel in row:
            char_index = int(pixel / 255 * (len(chars) - 1))
            line += chars[char_index]
        text_lines.append(line)
    
    return "\n".join(text_lines)

def assess_content(brightness, bright_ratio, edge_ratio):
    """Assess what the image likely contains"""
    assessment = []
    
    if brightness < 20:
        assessment.append("âŒ VERY DARK: Camera may be covered, in complete darkness, or malfunctioning")
    elif brightness < 50:
        assessment.append("ğŸŒ™ DARK ENVIRONMENT: Low light conditions, possibly nighttime or dim room")
    elif brightness < 100:
        assessment.append("ğŸ  INDOOR LIGHTING: Moderate indoor lighting conditions")
    elif brightness < 180:
        assessment.append("â˜€ï¸ WELL LIT: Good lighting conditions")
    else:
        assessment.append("ğŸ”† VERY BRIGHT: Strong lighting or overexposed")
    
    if bright_ratio > 0.3:
        assessment.append("âœ¨ High contrast with bright areas visible")
    elif bright_ratio > 0.1:
        assessment.append("ğŸ”¹ Some bright areas detected")
    else:
        assessment.append("âš« Mostly dark with few bright spots")
    
    if edge_ratio > 0.1:
        assessment.append("ğŸ”³ Complex scene with visible objects/details")
    elif edge_ratio > 0.05:
        assessment.append("ğŸ“ Some geometric features detected")
    else:
        assessment.append("ğŸŒ«ï¸ Uniform or blurred content")
    
    return "\n".join(f"â€¢ {item}" for item in assessment)

if __name__ == "__main__":
    # Analyze the most recent working frame
    working_frame = "/home/aaron/opencodeproject/working_frame_0.jpg"
    
    if Path(working_frame).exists():
        result = analyze_captured_image(working_frame)
        print(result)
    else:
        print("No working frame found. Taking new capture...")
        
        # Take a fresh capture
        import cv2
        cam = cv2.VideoCapture(0)
        if cam.isOpened():
            ret, frame = cam.read()
            if ret:
                cv2.imwrite(working_frame, frame)
                print(f"New frame captured: {working_frame}")
                result = analyze_captured_image(working_frame)
                print(result)
            cam.release()
        else:
            print("Could not access camera")